---
title: "Airwolf trap remix"
author: "Matt Crump"
date: 2/18/24
description: "Once I started I couldn't stop."
image: "cover.jpg"
comments:
  giscus: 
    repo: CrumpLab/crumplab_comments
categories: 
  - airwolf
  - nes
  - midi remix
execute: 
  echo: true
  message: false
  warning: false
  eval: false
format:
  html:
    code-fold: true
---

```{r}

```

```{python, eval = FALSE}
from diffusers import DiffusionPipeline
from transformers import set_seed
from PIL import Image
import torch
import random
import ssl
import os
ssl._create_default_https_context = ssl._create_unverified_context

#locate library
#model_id = "./stable-diffusion-v1-5"
model_id = "dreamshaper-xl-turbo"

pipeline = DiffusionPipeline.from_pretrained(
	pretrained_model_name_or_path = "../../../../bigFiles/huggingface/dreamshaper-xl-turbo/"
)

pipeline = pipeline.to("mps")

# Recommended if your computer has < 64 GB of RAM
pipeline.enable_attention_slicing("max")

prompt = "Chunky square wave. house beats. convolution reverb. A little dark analog delay. lots of stereo. busy. synthesizers. megazord. linocut"

for s in range(30):
  for n in [5,10]:
    seed = s+21
    num_steps = n+1
    set_seed(seed)
    
    image = pipeline(prompt,height = 1024,width = 1024,num_images_per_prompt = 1,num_inference_steps=num_steps)
    
    image_name = "images/synth_{}_{}.jpeg"
    
    image_save = image.images[0].save(image_name.format(seed,num_steps))

```

![](cover.jpg){width="50%" fig-align="left"}

::: column-margin
Screenshot from Airwolf for NES
:::

```{r}
#| echo: false
#| eval: true

html_tag_audio <- function(file, type = c("wav")) {
  type <- match.arg(type)
  htmltools::tags$audio(
    controls = "",
    htmltools::tags$source(
      src = file,
      type = glue::glue("audio/{type}", type = type)
    )
  )
}

```


Continuing in the glorious tradition of screwing around with NES midi files.

## Airwolf trap remix

`r html_tag_audio("Airwolf.mp3", type = "wav")`
