---
title: "D major practice"
author: "Matt Crump"
date: 1/8/24
description: "practice notes"
image: "cover.jpg"
comments:
  giscus: 
    repo: CrumpLab/crumplab_comments
categories: 
  - practice
execute: 
  echo: false
---

```{python, eval = FALSE}
from diffusers import DiffusionPipeline
from transformers import set_seed
from PIL import Image
import torch
import random
import ssl
import os
ssl._create_default_https_context = ssl._create_unverified_context

#locate library
#model_id = "./stable-diffusion-v1-5"
model_id = "LCM_Dreamshaper_v7"

pipeline = DiffusionPipeline.from_pretrained(
	pretrained_model_name_or_path = "../../../../bigFiles/huggingface/LCM_Dreamshaper_v7/",custom_pipeline="latent_consistency_txt2img", custom_revision="main", revision="fb9c5d"
)

pipeline = pipeline.to("mps")

# Recommended if your computer has < 64 GB of RAM
pipeline.enable_attention_slicing("max")

prompt = "D major scale. Piano. Circle of fifths. D major 7th chords played on an infinite universe piano. synthesizer keyboard universe."

image = pipeline(prompt,height = 1024,width = 1024,num_images_per_prompt = 4, num_inference_steps = 8)

image_save = image.images[0].save("cover_0.jpg")
image_save = image.images[1].save("cover_1.jpg")
image_save = image.images[2].save("cover_2.jpg")
image_save = image.images[3].save("cover_3.jpg") 

```


![](cover.jpg){width=50% fig-align="left"}


::: column-margin
"D major scale. Piano. Circle of fifths. D major 7th chords played on an infinite universe piano. synthesizer keyboard universe." - dreamshaper-xl-turbo
:::

```{r}
#| echo: false
html_tag_audio <- function(file, type = c("wav")) {
  type <- match.arg(type)
  htmltools::tags$audio(
    controls = "",
    htmltools::tags$source(
      src = file,
      type = glue::glue("audio/{type}", type = type)
    )
  )
}

```

Continuing from yesterday's G major practice I moved onto D major.

Played the D major scale up and down using 7th chords. Did this multiple times with each inversion.

Noted that I liked the sound of the 3rd inversion the best. Ran up and down enough times that I could play fairly fluently, almost into melody territory. Will likely continue this sort of practice across other keys.

---------------

Aside...I've been messing around with huggingface models as a possible way to generate visual stimuli for some experiments this semester. The class of latent consistency models can generate decent images fairly quickly. This morning I downloaded the "dreamshaper-xl-turbo" model to test it out. Today's blog picture was generated from this model. 


