---
title: "Assessing my 7th chords with a reaction time test"
author: "Matt Crump"
date: 1/19/24
description: "I made a jspsych task to test how fast I can play 7th chords."
image: "cover.jpg"
comments:
  giscus: 
    repo: CrumpLab/crumplab_comments
categories: 
  - practice
  - 7th chords
  - jspsych
  - assessment
execute: 
  echo: false
  message: false
  warning: false
---

```{python, eval = FALSE}
from diffusers import DiffusionPipeline
from transformers import set_seed
from PIL import Image
import torch
import random
import ssl
import os
ssl._create_default_https_context = ssl._create_unverified_context

#locate library
#model_id = "./stable-diffusion-v1-5"
model_id = "dreamshaper-xl-turbo"

pipeline = DiffusionPipeline.from_pretrained(
	pretrained_model_name_or_path = "../../../../bigFiles/huggingface/dreamshaper-xl-turbo/"
)

pipeline = pipeline.to("mps")

# Recommended if your computer has < 64 GB of RAM
pipeline.enable_attention_slicing("max")

prompt = "top of the picture, Repeated shapes in a row. Bottom, random shapes everywhere"

for s in range(30):
  for n in [4,5,6,7]:
    seed = s+1
    num_steps = n+1
    set_seed(seed)
    
    image = pipeline(prompt,height = 1024,width = 1024,num_images_per_prompt = 1,num_inference_steps=num_steps)
    
    image_name = "images/synth_{}_{}.jpeg"
    
    image_save = image.images[0].save(image_name.format(seed,num_steps))

```

![](cover.jpg){width="50%" fig-align="left"}

::: column-margin
Testing myself on 7th chords using a choice-reaction time procedure
:::

```{r}
#| echo: false
html_tag_audio <- function(file, type = c("wav")) {
  type <- match.arg(type)
  htmltools::tags$audio(
    controls = "",
    htmltools::tags$source(
      src = file,
      type = glue::glue("audio/{type}", type = type)
    )
  )
}

```

This post is about collecting some performance data on my ability to play stuff. I have some longer term plans to improve on these methods for research purposes, but for now I'm just interested in roughly tracking my own abilities.

In my last post I was about try out some different practice schedules, one of which would require me to randomly pick which keys to practice. That kind of stuff is annoying to do without a computer. Plus, if I'm about to collect a bunch of data in a bunch of conditions, I'd rather not code things and do data entry by hand.

So, I jumped ship and decided to start building little computerized measurement tools. 

I put together a really simple choice reaction test using [jspsych](https://www.jspsych.org/7.3/), the same javascript library I use for online cognition experiments. 

To start with I decided to test myself on basic 7th chords in all keys. There are 12 different keys, and for this test I used âˆ†7, 7, and -7 chords, for a total of 36 different chords. 

The choice-reaction time test is very simple. The program takes all of the possible chord names, randomly shuffles, then presents each name on the screen one at a time. I put my laptop ontop of my piano, waited for the chord name to come on, and then played the chord as fast as I could on the piano. At the same time, I had my left thumb on my spacebar, and I pressed the spacebar roughly at the same time that I played the chord. This allowed me to measure the chord reaction time for each chord. I also had the program repeat all the chords randomly twice, so that I get two reaction time measures per chord. 

I love jspsych. It took like 15 minutes to make this happen (granted, I have a bunch of prior experience using that library, and I was doing something very simple). Still, I already made the program and ran the test, and collected the data as a JSON variable. Woo hoo!

And, of course, this is really messy data. Ideally I would have the reaction times for each note, say using MIDI or something. But, that's for later.

I'd really like to take a look at my own performance data. I know all of these chords pretty well, but I have never closely compared my ability to produce them on demand. I expect I'll be pretty good in C, D, F, G, A, and worse in the other keys. But, I don't really know what the pattern looks like.

So, let's get to the data analysis. 

I loaded in the data, computed the average chord-reaction time for each chord, and put them all in the following table and graph.

```{r}
library(dplyr)
library(tidyverse)
library(jsonlite)
library(xtable)
library(data.table)

# Read the text file from JATOS ...
read_file('jatos_results_data_20240119133936.txt') %>%
  # ... split it into lines ...
  str_split('\n') %>% first() %>%
  # ... filter empty rows ...
  discard(function(x) x == '') %>%
  # ... parse JSON into a data.frame
  map_dfr(fromJSON, flatten=T) -> all_data

filtered_data <- all_data %>%
  filter(response != 0)

mean_data <- filtered_data %>%
  group_by(stimulus) %>%
  summarise(mean_rt = mean(rt))

DT::datatable(mean_data)
```

```{r}
#| fig-height: 7
#| fig-width: 7
plot_data <- mean_data %>%
  ungroup() %>%
  arrange(desc(mean_rt), .by_group = TRUE)

levels(plot_data$stimulus) <- plot_data$stimulus

ggplot(plot_data, aes(x=stimulus,y=mean_rt))+
  scale_x_discrete(limits= levels(plot_data$stimulus))+
  geom_bar(stat='identity')+
  coord_flip()
  
```

Neat. Close to what I expected in terms of which chords I think I'm better at. All of em could do with some extra practice. I suppose I should do more practice on the slow ones, because the fast ones don't really need it.

-----------------------------

I was too hasty with my jspsych programming and totally forget to add a few things that would make data-analysis much easier. I'd like to be able to easily replot the data in a few different ways. One is to group by maj7, min7, and dominant 7th. Another is to arrange the keys in ascending/descending order (rather than alphabetically), or in order of the circle of fifths. I could add the necessary factor levels to the data file by hand, but I think I'll add this to jspsych program so that the data file includes this by default. 

So, off to fixing the program, and then I'll collect some more data and try a few different plots.

And, I'm back. I ran through the practice one more time. Now my data file should be easier to plot in different ways.

Here is the mean chord reaction time for each key, grouped separately for each 7th chord.

```{r}

# Read the text file from JATOS ...
read_file('jatos_results_data_20240119143040.txt') %>%
  # ... split it into lines ...
  str_split('\n') %>% first() %>%
  # ... filter empty rows ...
  discard(function(x) x == '') %>%
  # ... parse JSON into a data.frame
  map_dfr(fromJSON, flatten=T) -> all_data

filtered_data <- all_data %>%
  filter(task == "practice_trial") %>%
  mutate(key = reorder(key,ascending_order))
  

mean_data <- filtered_data %>%
  group_by(key,chord) %>%
  summarise(mean_rt = mean(rt))

ggplot(mean_data, aes(x = key, y = mean_rt, fill = chord))+
  geom_bar(stat="identity", position = 'dodge')

```
I wanted to be able to order the keys in terms of the circle of fifths, but there was another bug in the code, now fixed. But, I'll need another round of data-collection to get that graph.

In terms of piano practice, it looks like I need to get a bunch of these chord reaction times lower. Especially Gb, Ab, Bb, Eb, and Db, and B. I thought Bb would be better, but nope.

The program I have written is not currently keeping track of practice attempts per chord, and I should add that in I think.

---------------------------

After some javascript nonsense, the program now runs in a loop. Each loop through a set of practice material it also records the practice attempt number. 

My loop of practice material is all the basic 7th chords. So, I'm about to practice them on loop for a while and then plot the data.

One detail is whether to do away with the delay between trials. Right now I play the chord and there is a 2 second delay before the next chord. That's nice and everything, but I feel like chomping through this, so maybe I will get rid of that delay.

----------------------

I practiced all the chords in a random order for about 10 times each. This is a plot of my chord reaction time as a function of practice for all chords. A bit messy to look.


```{r}

# Read the text file from JATOS ...
read_file('jatos_results_data_20240119161739.txt') %>%
  # ... split it into lines ...
  str_split('\n') %>% first() %>%
  # ... filter empty rows ...
  discard(function(x) x == '') %>%
  # ... parse JSON into a data.frame
  map_dfr(fromJSON, flatten=T) -> all_data

filtered_data <- all_data %>%
  filter(task == "practice_trial") %>%
  mutate(key = reorder(key,ascending_order))
  
ggplot(filtered_data, aes(x = repetition, 
                          y = rt, 
                          group = key,
                          color = key))+
  geom_line()+
  geom_point()+
  facet_wrap(~chord)

```

If I average over keys, did I get any better?

There's a downward trend I guess.

```{r}
mean_data <- filtered_data %>%
  filter(rt <= 6000,
         rt >= 1000) %>%
  group_by(repetition, chord) %>%
  summarize(mean_rt = mean(rt))


  
ggplot(mean_data, aes(x = repetition, 
                          y = mean_rt,
                      color = chord))+
  geom_line()+
  geom_point()
```

Averaging over chords and showing the individual keys:

```{r}
mean_data <- filtered_data %>%
  filter(rt <= 6000,
         rt >= 1000) %>%
  group_by(repetition, key) %>%
  summarize(mean_rt = mean(rt))


  
ggplot(mean_data, aes(x = repetition, 
                          y = mean_rt,
                      color = key))+
  geom_line()+
  geom_point()+
  facet_wrap(~key)
```

And, one last summary graph. Let's average over repetitions, and arrange by the circle of fifths.

```{r}
mean_data <- filtered_data %>%
  mutate(key = reorder(key,fifths_order)) %>%
  filter(rt <= 6000,
         rt >= 1000) %>%
  group_by(key) %>%
  summarize(mean_rt = mean(rt))


  
ggplot(mean_data, aes(x = key, 
                          y = mean_rt,
                      color = key))+
  geom_bar(stat = 'identity', position = "dodge")
```

I guess I should practice Gb and Db and Bb and flatten out this performance distribution. 

-----------------------------

Alright, that's basically all I wanted to accomplish today. Now I have a clunky little tool to relatively quickly assess where I am at on different musical elements. Time to go do something else.

